# AUTOGENERATED! DO NOT EDIT! File to edit: ../00_titanic_from_scratch.ipynb.

# %% auto 0
__all__ = ['start_time', 'debug', 'parser', 'args', 'path', 'line_char_width', 'df', 'mode', 't_dep', 'indep_columns', 't_indep',
           'trn', 'val', 'trn_indep', 'val_indep', 'trn_dep', 'val_dep', 'calc_preds', 'calc_loss']

# %% ../00_titanic_from_scratch.ipynb 0
# |export
#|default_exp p00_titanic_from_scratch


# %% ../00_titanic_from_scratch.ipynb 1
import os
import time
import pathlib
import argparse
import torch
from torch import tensor



# %% ../00_titanic_from_scratch.ipynb 2
start_time=time.time()
debug=True
_code_git_version="6c2f9a414e8bda5836211266611729864e5ea993"
_code_repository="https://github.com/plops/cl-py-generator/tree/master/example/96_colab_fastai/source/"
_code_generation_time="19:07:01 of Sunday, 2022-08-28 (GMT+1)"
start_time=time.time()
debug=True


# %% ../00_titanic_from_scratch.ipynb 3
parser=argparse.ArgumentParser()
parser.add_argument("-v", "--verbose", help="enable verbose output", action="store_true")
args=parser.parse_args()


# %% ../00_titanic_from_scratch.ipynb 4
path=pathlib.Path("titanic")
if ( not(path.exists()) ):
    import zipfile
    import kaggle
    kaggle.api.competition_download_cli(str(path))
    zipfile.ZipFile(f"{path}.zip").extractall(path)


# %% ../00_titanic_from_scratch.ipynb 5
import torch
import numpy as np
import pandas as pd
line_char_width=140
np.set_print_options(linewidth=line_char_width)
torch.set_print_options(linewidth=line_char_width, sci_mode=False, edgeitems=7)
pd.set_option("display_width", line_char_width)


# %% ../00_titanic_from_scratch.ipynb 6
df=pd.read_csv(((path)/("train.csv")))
df


# %% ../00_titanic_from_scratch.ipynb 8
mode=df.mode().iloc[0]


# %% ../00_titanic_from_scratch.ipynb 9
df.fillna(modes, inplace=True)


# %% ../00_titanic_from_scratch.ipynb 13
df["LogFare"]=np.log(((1)+(df.Fare)))


# %% ../00_titanic_from_scratch.ipynb 17
# replace non-numeric values with numbers by introducing new columns (dummies). The dummy columns will be added to the dataframe df and the 3 original columns are dropped.
# Cabin, Name and Ticket contain too many unique values for this approach to be useful
df=pd.get_dummies(df, columns=["Sex", "Pclass", "Embarked"])
df.columns


# %% ../00_titanic_from_scratch.ipynb 19
# create dependent variable as tensor
t_dep=tensor(df.Survived)


# %% ../00_titanic_from_scratch.ipynb 20
# independent variables are all continuous variables of interest and the newly created columns
indep_columns=((["Age", "SipSp", "Parch", "LogFare"])+(added_columns))
t_indep=tensor(df[indep_columns].values, dtype=torch.float)
t_indep


# %% ../00_titanic_from_scratch.ipynb 28
# using what we learned in the previous cells create functions to compute predictions and loss
def calc_preds(coeffs=None, indeps=None):
    return ((indeps)*(coefs)).sum(axis=1)
def calc_loss(coeffs=None, indeps=None, deps=None):
    preds=calc_preds(coeffs=coeffs, indeps=indeps)
    loss=torch.abs(((preds)-(deps))).mean()
    return loss


# %% ../00_titanic_from_scratch.ipynb 34
# before we can perform training, we have to create a validation dataset
# we do that in the same way as the fastai library does
import fastai.data.transforms
# get training (trn) and validation indices (val)
trn, val=(fastai.data.transforms.RandomSplitter(seed=42))((df))


# %% ../00_titanic_from_scratch.ipynb 35
trn_indep=t_indep[trn]
val_indep=t_indep[val]
trn_dep=t_dep[trn]
val_dep=t_dep[val]
len(trn_indep), len(val_indep)

