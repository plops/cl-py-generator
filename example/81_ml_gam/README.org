- https://www.youtube.com/watch?v=sgw4cu8hrZM Introduction to
  Generalized Additive Models with R and mgcv

- https://twitter.com/jeremyphoward/status/1194388187042349056 I've
  wondered about the total lack of awareness or interest in penalized
  logistic regression with splines for a couple of decades now. It's
  such an awesome approach.  Perhaps we need better library support to
  make it more accessible? Or is it just an education issue?

  2015 Harrell Regression Modeling Strategies With Applications to
  Linear Models, Logistic and Ordinal Regression and Survival Analysis
  
- https://pygam.readthedocs.io/en/latest/notebooks/tour_of_pygam.html#Classification
  - https://www.linkedin.com/in/charlie-brummitt/
  - https://www.youtube.com/watch?v=XQ1vk7wEI7c pyGAM: balancing
    interpretability and predictive power using... - Dani Servén Marín
    - generalized cross validation to find out how many splines to use
    - .fit -> .gridsearch choose between 100 parameter settings
    - histogram smoothing models counts in each bin as poisson
   

- penalized regression splines 
  - mgcv r package
  - simon wood Generalized Additive Models: An Introduction with R
    
- https://www.youtube.com/watch?v=sgw4cu8hrZM Introduction to
  Generalized Additive Models with R and mgcv
  - https://youtu.be/sgw4cu8hrZM?t=3658 amazing 2d map of occurrance
    off bird, no plots :-(
  - https://youtu.be/sgw4cu8hrZM 2d plots temperature vs time on a map
    in a bay

- https://harvard-iacs.github.io/2020-CS109B/labs/lab02/notebook/
  - statsmodels
  - pyGAM
    - linearGAM on wages dataset, unfortunately no discussion/interpretation


* smoothing
  - 5.1.2 smoothing splines have as many free parameters as there are
    data to be smoothed
    - smoothing penalty often suppresses many degrees of freedom
    - stable O(n) algorithm exists for univariate smoothing with cubic
      splines (hoog, hutchinson 1987)
    - with more covariates computation becomes expensive
  - 5.2 set k = O(n^(1/9)) to obtain mean square error rate of
    O(n^(-8/9)) for (penalized) regression splines
    - with penalization k = O(n^(1/5))
    - I don't really understand the argument. Apparently, they have no
      good theory. However, basis dimension only needs to grow slowly
      with sample size in order to achieve statistical performance
      asymptotically indistinguishable from that of a full smoothing
      spline.
  - 5.3 1d smoothers
    - cubic penalized regression splines
#+begin_example
k knots x[1] .. x[k]
b[j] = f(x[j])
d[j] = f''(x[j])

f(x) = a[j](x)b[j] + A[j]b[j+1] + c[j](x)d[j] + C[j](x)d[j+1]  for x[j]<=x<=x[j+1]
a[j](x) = (x[j+1]-x)/h[j]
A[j](x) = (x-x[j])/h[j]
c[j](x) = ((x[j+1]-x)^3/h[j]-h[j]*(x[j+1]-x))/6
C[j](x) = ((x-x[j])^3/h[j]-h[j]*(x-x[j]))/6

D[i,i]   = 1/h[i]
D[i,i+1] = -1/h[i] - 1/h[i+1]
D[i,i+2] = 1/h[i+1]
B[i,i]   = (h[i] + h[i+1])/3    for i = 1..k-2
B[i,i+1] = B[i+1,i] = h[i+1]/6  for i = 1..k-3
#+end_example
      - cyclic version
    - thin plate regression spliens
